training:
  dataset_name: librispeech100h
  output_dir: checkpoints/MelCausalVAE/aligner-vits # variable rate training
  num_train_epochs: 5
  learning_rate: 1e-4
  per_device_train_batch_size: 24
  report_to: none
  wandb_project: flexi-vae
  wandb_run_name: aligner-vits
  fp16: false
  bf16: true
  save_steps: 1000
  eval_strategy: "steps"
  eval_steps: 100
  save_total_limit: 1
  gradient_accumulation_steps: 1
  dataloader_num_workers: 4
  min_learning_rate: 5e-5
  from_pretrained: /workspace/MelCausalVAE/checkpoints/no-aligner/checkpoint-10000/model.safetensors
  #resume_from_checkpoint: /workspace/MelCausalVAE/checkpoints/MelCausalVAE/aligner-ft/checkpoint-1000
  phonemes: true

convformer:
  compress_factor_C: 4
  tf_heads: 8
  tf_layers: 4
  latent_dim: 64
  logvar_layer: false
  use_sofplus: false
  target_std: 1.0
  kl_loss_warmup_steps: 500
  kl_loss_weight: 1e-3
  use_aligner: true
  freeze_encoder: true
  threshold: 0.90

cfm:
  unet_dim: 1024
  unet_depth: 4
  unet_heads: 8
  unet_dropout_rate: 0.1
  use_conv_layer: true
  audio_latent_dim: 64
  uncond_prob: 0.15
  learned_prior: false
  is_causal: true
  decoder_type: "dit"