# Configuration for training Z2Y mapper
# Only specify values that override defaults in configs/defaults/*.yaml
#
# Z2Y Mapper Architecture:
#   z [B, T, 64] -> bottleneck [B, T, 48] -> y [B, T, 64]
#
# Loss components:
#   - semantic_loss: InterpolateRegulator computes cosine similarity between y and SeamlessM4Tv2 features
#   - cons_loss: MSE(y, z) to maintain consistency with original latents
#   - total_loss = semantic_loss + lambda_cons * cons_loss

training:
  output_dir: checkpoints/MelCausalVAE/semantic_mapper
  dataset_name: libritts
  num_train_epochs: 10
  learning_rate: 1e-4
  per_device_train_batch_size: 16
  report_to: wandb
  wandb_project: z2y-mapper
  wandb_run_name: z2y-mapper-baseline
  fp16: false
  bf16: true
  save_steps: 1000
  save_total_limit: 3
  gradient_accumulation_steps: 1
  logging_steps: 1
  resume_from_checkpoint: /home/ec2-user/checkpoints/MelCausalVAE/semantic_mapper/checkpoint-2000

# VAE encoder config (must match the pretrained checkpoint)
convformer:
  compress_factor_C: 8
  tf_heads: 8
  tf_layers: 4
  latent_dim: 64
  n_residual_blocks: 3
  logvar_layer: false
  use_sofplus: false
  target_std: 1.0
  kl_loss_warmup_steps: 1000
  kl_loss_weight: 1e-3

# VAE decoder config (must match the pretrained checkpoint)
cfm:
  unet_dim: 1024
  unet_depth: 8
  unet_heads: 16
  unet_dropout_rate: 0.1
  use_conv_layer: true
  audio_latent_dim: 64
  uncond_prob: 0.1
  is_causal: true

# Z2Y mapper specific config
semantic_mapper:
  bottleneck_dim: 48  # Bottleneck dimension (z_dim -> bottleneck -> z_dim)
  dropout: 0.1  # Dropout rate in the mapper
  lambda_cons: 0.2  # Weight for consistency loss MSE(y, z)

